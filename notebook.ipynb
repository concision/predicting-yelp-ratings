{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1 style=\"text-align: center\">Yelp Rating Prediction</h1>\n",
    "<hr style=\"border-top: 1px solid #444\">"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Development Environment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# python typings\n",
    "from typing import TypedDict, Dict, List\n",
    "import json, time\n",
    "# libraries\n",
    "import sys, numpy, pandas, sklearn, tensorflow\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Numpy {numpy.__version__}\")\n",
    "print(f\"Pandas {pandas.__version__}\")\n",
    "print(f\"Scikit-Learn {sklearn.__version__}\")\n",
    "print(f\"Tensor Flow Version: {tensorflow.__version__} (Keras Version: {tensorflow.keras.__version__})\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.8.5 (tags/v3.8.5:580fbb0, Jul 20 2020, 15:57:54) [MSC v.1924 64 bit (AMD64)]\n",
      "Numpy 1.18.5\n",
      "Pandas 1.1.1\n",
      "Scikit-Learn 0.23.2\n",
      "Tensor Flow Version: 2.3.0 (Keras Version: 2.4.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr style=\"border-top: 1px solid #444\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# I. Data Importation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset Location"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "file_businesses = r\"data/yelp_academic_dataset_business.json\"\n",
    "file_user_reviews = r\"data/yelp_academic_dataset_review.json\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Yelp Businesses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 209,393 distinct businesses in 3.433064 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# business structure\n",
    "class Business(TypedDict):\n",
    "    business_id: str\n",
    "    name: str\n",
    "    address: str\n",
    "    city: str\n",
    "    state: str\n",
    "    postal_code: str\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    stars: float\n",
    "    review_count: int\n",
    "    is_open: int\n",
    "    attributes: Dict\n",
    "    categories: List[str]\n",
    "    hours: Dict\n",
    "\n",
    "# businesses indexed by business_id (i.e. {business['business_id']: Business}\n",
    "businesses_by_id: Dict[str, Business] = {}\n",
    "\n",
    "# parse all businesses\n",
    "with open(file_businesses, 'r', encoding='utf-8') as file:\n",
    "    # iterate over newline-deliminted JSON records\n",
    "    record: str\n",
    "    for record in file:\n",
    "        # parse JSON record\n",
    "        business: Business = json.loads(record)\n",
    "        # map Business by business_id\n",
    "        businesses_by_id[business['business_id']] = business\n",
    "\n",
    "print(f\"Imported {len(businesses_by_id):,} distinct businesses in {time.time() - start_time:.6f} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import User Review Texts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 8,021,122 user reviews in 73.749091 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# user review structure\n",
    "class UserReview(TypedDict):\n",
    "    review_id: str\n",
    "    user_id: str\n",
    "    business_id: str\n",
    "    date: str\n",
    "    stars: int # [0, 1, 2, 3, 4, 5]\n",
    "    text: str\n",
    "    # review ratings\n",
    "    useful: int\n",
    "    funny: int\n",
    "    cool: int\n",
    "\n",
    "# user reviews indexed by business_id (i.e. {business_id: UserReview[]})\n",
    "business_review_texts: Dict[str, List[str]] = {\n",
    "    business_id: [] for business_id in businesses_by_id.keys()\n",
    "}\n",
    "\n",
    "# parse user reviews\n",
    "with open(file_user_reviews, 'r', encoding='utf-8') as file:\n",
    "    # iterate over newline-deliminted JSON records\n",
    "    record: str\n",
    "    for record in file:\n",
    "        # parse JSON record\n",
    "        review: UserReview = json.loads(record)\n",
    "        # map user review by business_id\n",
    "        business_review_texts[review['business_id']].append(review[\"text\"])\n",
    "\n",
    "print(f\"Imported {sum([len(reviews) for reviews in business_review_texts.values()]):,} user reviews in {time.time() - start_time:.6f} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr style=\"border-top: 1px solid #444\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## II. Training Data Selection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Select businesses with more than X reviews"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103,803 selected businesses (filtered 105590) in 0.117991 seconds\n"
     ]
    }
   ],
   "source": [
    "# minimum business[\"review_count\"] required for a business to not be filtered\n",
    "MINIMUM_REVIEW_COUNT = 10\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# filter out businesses with less than MINIMUM_REVIEW_COUNT reviews\n",
    "filtered_businesses = [business for business in businesses_by_id.values() if MINIMUM_REVIEW_COUNT <= business[\"review_count\"]]\n",
    "\n",
    "print(f\"{len(filtered_businesses):,} selected businesses (filtered {len(businesses_by_id) - len(filtered_businesses)}) in {time.time() - start_time:.6f} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Partition businesses for model training and testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioned 20,000 businesses into {training: 10000, testing: 10000} in 0.109395 seconds\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "# \"represents the absolute number of test samples\"\n",
    "TRAINING_SIZE = 10_000\n",
    "# \"represents the absolute number of train samples\"\n",
    "TESTING_SIZE = 10_000\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# split businesses into two disjoint subsets: training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_businesses: List[Business]\n",
    "test_businesses: List[Business]\n",
    "train_businesses, test_businesses = train_test_split(\n",
    "    # set to partition\n",
    "    filtered_businesses,\n",
    "    # partition proportions\n",
    "    train_size = TRAINING_SIZE,\n",
    "    test_size = TESTING_SIZE,\n",
    "    # shuffle the data\n",
    "    shuffle = True,\n",
    "    # PRNG seed for deterministic behaviour\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "print(f\"Partitioned {len(train_businesses) + len(test_businesses):,} businesses into {{training: {len(train_businesses)}, testing: {len(test_businesses)}}} in {time.time() - start_time:.6f} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr style=\"border-top: 1px solid #444\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# III. Model Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Input Features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Concatenate User Reviews"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 20,000 businesses in 1.157176 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# concatenated user review texts indexed by business_id (i.e. {business_id: review_text}})\n",
    "business_concatenated_reviews: Dict[str, str] = {}\n",
    "\n",
    "# process each business in the training and testing datasets\n",
    "business: Business\n",
    "for business in train_businesses + test_businesses:\n",
    "    business_id: str = business['business_id']\n",
    "    business_concatenated_reviews[business_id] = \"\\n\".join(business_review_texts[business_id])\n",
    "\n",
    "# metrics\n",
    "print(f\"Processed {len(train_businesses) + len(test_businesses):,} businesses in {time.time() - start_time:.6f} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Vectorize review texts using TFIDF vectorization NLP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training matrix shape: (10000, 500)\n",
      "Word features cardinality: 500\n",
      "Word features: ['00', '10', '12', '15', '20', '30', '50', 'able', 'absolutely', 'actually', 'add', 'ago', 'amazing', 'appetizer', 'appointment', 'area', 'arrived', 'ask', 'asked', 'ate', 'atmosphere', 'attentive', 'authentic', 'available', 'average', 'away', 'awesome', 'bacon', 'bad', 'bar', 'bbq', 'beautiful', 'beef', 'beer', 'believe', 'best', 'better', 'big', 'birthday', 'bit', 'bite', 'bowl', 'bread', 'breakfast', 'bring', 'brought', 'brunch', 'buffet', 'burger', 'burgers', 'business', 'busy', 'buy', 'cake', 'called', 'came', 'car', 'card', 'care', 'change', 'charge', 'cheap', 'check', 'cheese', 'chef', 'chicken', 'chips', 'chocolate', 'choice', 'choose', 'clean', 'close', 'coffee', 'cold', 'come', 'comes', 'comfortable', 'coming', 'company', 'completely', 'cooked', 'cool', 'cost', 'couldn', 'counter', 'couple', 'course', 'crab', 'cream', 'crispy', 'curry', 'customer', 'customers', 'cut', 'day', 'days', 'deal', 'decent', 'decided', 'decor', 'definitely', 'delicious', 'dessert', 'did', 'didn', 'different', 'dining', 'dinner', 'disappointed', 'dish', 'dishes', 'does', 'doesn', 'dog', 'doing', 'don', 'door', 'dr', 'drink', 'drinks', 'drive', 'dry', 'early', 'easy', 'eat', 'eating', 'egg', 'eggs', 'employees', 'end', 'ended', 'enjoy', 'enjoyed', 'entire', 'especially', 'evening', 'excellent', 'expect', 'expected', 'expensive', 'experience', 'extra', 'extremely', 'fact', 'family', 'fan', 'fantastic', 'far', 'fast', 'favorite', 'feel', 'felt', 'finally', 'fine', 'fish', 'flavor', 'flavors', 'floor', 'food', 'free', 'french', 'fresh', 'friday', 'fried', 'friend', 'friendly', 'friends', 'fries', 'fun', 'garlic', 'gave', 'gets', 'getting', 'girl', 'given', 'glad', 'glass', 'going', 'gone', 'good', 'got', 'great', 'green', 'grilled', 'group', 'guess', 'guy', 'guys', 'hair', 'half', 'happy', 'hard', 'haven', 'having', 'heard', 'help', 'helpful', 'high', 'highly', 'home', 'horrible', 'hot', 'hotel', 'hour', 'hours', 'house', 'huge', 'husband', 'ice', 'immediately', 'impressed', 'inside', 'instead', 'isn', 'issue', 'italian', 'items', 'job', 'just', 'kept', 'kids', 'kind', 'kitchen', 'knew', 'know', 'lady', 'large', 'las', 'late', 'later', 'leave', 'left', 'let', 'life', 'light', 'like', 'liked', 'line', 'list', 'literally', 'little', 'live', 'll', 'lobster', 'local', 'location', 'long', 'look', 'looked', 'looking', 'looks', 'lot', 'lots', 'love', 'loved', 'lunch', 'main', 'make', 'makes', 'making', 'man', 'manager', 'massage', 'maybe', 'meal', 'meat', 'menu', 'mexican', 'milk', 'mind', 'minutes', 'money', 'month', 'months', 'morning', 'moved', 'music', 'nails', 'near', 'need', 'needed', 'needs', 'new', 'nice', 'night', 'noodles', 'offer', 'offered', 'office', 'oh', 'ok', 'okay', 'old', 'open', 'options', 'order', 'ordered', 'ordering', 'orders', 'outside', 'overall', 'owner', 'paid', 'parking', 'party', 'past', 'pasta', 'patio', 'pay', 'people', 'perfect', 'perfectly', 'person', 'phone', 'pick', 'pizza', 'place', 'places', 'plate', 'plenty', 'plus', 'point', 'pool', 'pork', 'portion', 'portions', 'potato', 'potatoes', 'pretty', 'price', 'priced', 'prices', 'probably', 'problem', 'professional', 'quality', 'quick', 'quickly', 'quite', 'ready', 'real', 'really', 'reason', 'reasonable', 'received', 'recommend', 'recommended', 'red', 'regular', 'remember', 'restaurant', 'restaurants', 'return', 'review', 'reviews', 'rice', 'right', 'roll', 'rolls', 'room', 'rooms', 'rude', 'run', 'said', 'salad', 'salmon', 'salsa', 'sandwich', 'sandwiches', 'sat', 'saturday', 'sauce', 'saw', 'say', 'saying', 'seated', 'seating', 'second', 'seen', 'selection', 'serve', 'served', 'server', 'servers', 'service', 'set', 'shop', 'short', 'shrimp', 'simple', 'sit', 'sitting', 'size', 'slow', 'small', 'soft', 'soon', 'soup', 'space', 'special', 'spicy', 'spot', 'staff', 'star', 'stars', 'start', 'started', 'stay', 'steak', 'stop', 'stopped', 'store', 'street', 'strip', 'stuff', 'style', 'sunday', 'super', 'sure', 'sushi', 'sweet', 'table', 'tables', 'taco', 'tacos', 'taken', 'taking', 'taste', 'tasted', 'tasty', 'tea', 'tell', 'terrible', 'thai', 'thank', 'thanks', 'thing', 'things', 'think', 'thought', 'time', 'times', 'tip', 'today', 'told', 'took', 'totally', 'town', 'tried', 'trip', 'try', 'trying', 'twice', 'type', 'understand', 'unfortunately', 'use', 'used', 'usually', 'variety', 've', 'vegas', 'visit', 'wait', 'waited', 'waiter', 'waiting', 'waitress', 'walk', 'walked', 'walking', 'want', 'wanted', 'warm', 'wasn', 'water', 'way', 'week', 'weekend', 'weeks', 'went', 'white', 'wife', 'wine', 'wings', 'wish', 'won', 'wonderful', 'work', 'working', 'worst', 'worth', 'wouldn', 'wow', 'wrong', 'year', 'years', 'yelp', 'yes', 'yummy']\n",
      "IDF Vectorized 20,000 businesses review texts in 109.076089 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# construct vectorizer\n",
    "vectorizer: TfidfVectorizer = TfidfVectorizer(\n",
    "    # maximum word features\n",
    "    max_features = 500,\n",
    "    # prune english stop words\n",
    "    stop_words = 'english',\n",
    "    # min_df: ignore terms that have a document frequency < min_df.\n",
    "    # min_df = 10, (redundant for large data sets)\n",
    ")\n",
    "\n",
    "# construct corpus from training data\n",
    "train_reviews_tfidf = vectorizer.fit_transform(\n",
    "    [business_concatenated_reviews[business['business_id']] for business in train_businesses]\n",
    ").toarray()\n",
    "\n",
    "# transform corpus of testing data\n",
    "test_reviews_tfidf = vectorizer.transform(\n",
    "    [business_concatenated_reviews[business['business_id']] for business in test_businesses]\n",
    ").toarray()\n",
    "\n",
    "# metrics\n",
    "print(f\"Training matrix shape: {train_reviews_tfidf.shape}\")\n",
    "print(f\"Word features cardinality: {len(vectorizer.get_feature_names()):,}\")\n",
    "print(f\"Word features: {vectorizer.get_feature_names()}\")\n",
    "print(f\"IDF Vectorized {len(train_businesses) + len(test_businesses):,} businesses review texts in {time.time() - start_time:.6f} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Input Matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "\tFeatures shape: (10000, 500)\n",
      "Testing:\n",
      "\tFeatures shape: (10000, 500)\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "train_tf_input = train_reviews_tfidf\n",
    "print(\"Training:\")\n",
    "print(f\"\\tFeatures shape: {train_tf_input.shape}\")\n",
    "\n",
    "# testing\n",
    "test_tf_input = test_reviews_tfidf\n",
    "print(\"Testing:\")\n",
    "print(f\"\\tFeatures shape: {test_tf_input.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Output Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Star Rating"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_stars = numpy.array([[business['stars']] for business in train_businesses])\n",
    "test_stars = numpy.array([[business[\"stars\"]] for business in test_businesses])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Output Matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "\tFeatures shape: (10000, 1)\n",
      "Testing:\n",
      "\tFeatures shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "train_tf_output = train_stars\n",
    "print(\"Training:\")\n",
    "print(f\"\\tFeatures shape: {train_tf_output.shape}\")\n",
    "\n",
    "# testing\n",
    "test_tf_output = test_stars\n",
    "print(\"Testing:\")\n",
    "print(f\"\\tFeatures shape: {test_tf_output.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}